import os, logging
from typing import Optional

USE_VERTEX_MOCK = os.getenv("USE_VERTEX_MOCK", "false").lower() == "true"
PROJECT_ID = os.getenv("PROJECT_ID")
LOCATION = os.getenv("LOCATION", "europe-central2")
MODEL_NAME = os.getenv("MODEL_NAME", "gemini-2.5-flash")

logger = logging.getLogger("llm")

def _mock_generate(system_prompt: str, context: str, history: str, user_message: str) -> str:
    # ÐŸÑ€Ð¾ÑÑ‚Ð¸Ð¹ Ñ„Ð¾Ð»Ð±ÐµÐº Ð±ÐµÐ· Ð·Ð²ÐµÑ€Ð½ÐµÐ½Ð½Ñ Ð´Ð¾ Vertex AI (Ð´Ð»Ñ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¸Ñ… Ð´ÐµÐ¼Ð¾ Ð±ÐµÐ· ÐºÐ²Ð¾Ñ‚)
    return (
        f"ðŸ“Ž [ÐœÐžÐš-Ð’Ð†Ð”ÐŸÐžÐ’Ð†Ð”Ð¬]"
        f"System: {system_prompt[:80]}..."
        f"Context: {context[:120]}..."
        f"History(last): {history[:120]}..."
        f"User: {user_message}"
        "Assistant: Ð¦Ðµ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ñ–Ð¹Ð½Ð° Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÑŒ Ð±ÐµÐ· Ð²Ð¸ÐºÐ»Ð¸ÐºÑƒ Vertex AI. "
        "Ð£Ð²Ñ–Ð¼ÐºÐ½Ñ–Ñ‚ÑŒ Vertex, Ð²Ð¸ÑÑ‚Ð°Ð²Ð¸Ð²ÑˆÐ¸ USE_VERTEX_MOCK=false Ð² .env."
    )

def generate_answer(system_prompt: str, context: str, history: str, user_message: str) -> str:
    use_mock = os.getenv("USE_VERTEX_MOCK", "false").lower() == "true"
    if use_mock:
        return _mock_generate(system_prompt, context, history, user_message)
    try:
        import vertexai
        from vertexai.generative_models import GenerativeModel
    except Exception as e:
        logger.exception("VertexAI import failed")
        return _mock_generate(system_prompt, context, history, user_message)

    vertexai.init(project=PROJECT_ID or os.getenv("GOOGLE_CLOUD_PROJECT"), location=LOCATION)
    model = GenerativeModel(MODEL_NAME)

    prompt = (
        f"""{system_prompt}

        Context:
        {context}

        History:
        {history}

        User: {user_message}
        Assistant:"""
    )
    try:
        resp = model.generate_content(prompt)
        return (getattr(resp, "text", "") or "").strip()
    except Exception:
        logger.exception("VertexAI call failed")
        return _mock_generate(system_prompt, context, history, user_message)